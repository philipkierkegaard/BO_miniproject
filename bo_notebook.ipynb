{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Head:\n",
      "    alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  target  \n",
      "0                          3.92   1065.0       0  \n",
      "1                          3.40   1050.0       0  \n",
      "2                          3.17   1185.0       0  \n",
      "3                          3.45   1480.0       0  \n",
      "4                          2.93    735.0       0  \n",
      "Class Distribution:\n",
      " target\n",
      "1    71\n",
      "0    59\n",
      "2    48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = load_wine()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "print(\"Dataset Head:\\n\", df.head())\n",
    "print(\"Class Distribution:\\n\", df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 1.0\n",
      "Baseline Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=['target']), df['target'], test_size=0.2, random_state=42, stratify=df['target']\n",
    ")\n",
    "\n",
    "# Normalize Data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Baseline Model\n",
    "baseline_model = RandomForestClassifier(random_state=42)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "baseline_preds = baseline_model.predict(X_test)\n",
    "print(\"Baseline Accuracy:\", accuracy_score(y_test, baseline_preds))\n",
    "print(\"Baseline Classification Report:\\n\", classification_report(y_test, baseline_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-25 13:32:18,876] A new study created in memory with name: no-name-38bc5b33-5eb8-48dd-9a7e-8c9b5f8cf3ef\n",
      "[I 2025-02-25 13:32:18,003] Trial 0 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 120, 'max_depth': 19, 'min_samples_split': 20, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9790640394088669.\n",
      "[I 2025-02-25 13:32:19,379] Trial 1 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 243, 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.9790640394088669.\n",
      "[I 2025-02-25 13:32:20,909] Trial 2 finished with value: 0.97192118226601 and parameters: {'n_estimators': 279, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.9790640394088669.\n",
      "[I 2025-02-25 13:32:22,476] Trial 3 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 267, 'max_depth': 21, 'min_samples_split': 12, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.9790640394088669.\n",
      "[I 2025-02-25 13:32:23,565] Trial 4 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 200, 'max_depth': 19, 'min_samples_split': 19, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.9790640394088669.\n",
      "[I 2025-02-25 13:32:23,985] Trial 5 finished with value: 0.97192118226601 and parameters: {'n_estimators': 72, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.9790640394088669.\n",
      "[I 2025-02-25 13:32:24,854] Trial 6 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 162, 'max_depth': 19, 'min_samples_split': 13, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9790640394088669.\n",
      "[I 2025-02-25 13:32:26,441] Trial 7 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 285, 'max_depth': 3, 'min_samples_split': 11, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.9790640394088669.\n",
      "[I 2025-02-25 13:32:27,029] Trial 8 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 108, 'max_depth': 22, 'min_samples_split': 16, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.9790640394088669.\n",
      "[I 2025-02-25 13:32:27,436] Trial 9 finished with value: 0.97192118226601 and parameters: {'n_estimators': 73, 'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.9790640394088669.\n",
      "[I 2025-02-25 13:32:28,235] Trial 10 finished with value: 0.9862068965517242 and parameters: {'n_estimators': 138, 'max_depth': 28, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:28,957] Trial 11 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 130, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:29,921] Trial 12 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 175, 'max_depth': 29, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:30,617] Trial 13 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 122, 'max_depth': 26, 'min_samples_split': 20, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:31,765] Trial 14 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 208, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:32,588] Trial 15 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 147, 'max_depth': 13, 'min_samples_split': 17, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:33,128] Trial 16 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 97, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:33,452] Trial 17 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 51, 'max_depth': 25, 'min_samples_split': 16, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:34,589] Trial 18 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:35,442] Trial 19 finished with value: 0.9862068965517242 and parameters: {'n_estimators': 145, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:36,451] Trial 20 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 176, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:37,277] Trial 21 finished with value: 0.9862068965517242 and parameters: {'n_estimators': 144, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:38,135] Trial 22 finished with value: 0.9862068965517242 and parameters: {'n_estimators': 149, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:38,919] Trial 23 finished with value: 0.9862068965517242 and parameters: {'n_estimators': 140, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:39,432] Trial 24 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 94, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:40,372] Trial 25 finished with value: 0.9862068965517242 and parameters: {'n_estimators': 176, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:41,613] Trial 26 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 235, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:42,554] Trial 27 finished with value: 0.9862068965517242 and parameters: {'n_estimators': 163, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:43,610] Trial 28 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 188, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 10 with value: 0.9862068965517242.\n",
      "[I 2025-02-25 13:32:44,246] Trial 29 finished with value: 0.9790640394088669 and parameters: {'n_estimators': 112, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.9862068965517242.\n"
     ]
    }
   ],
   "source": [
    "# Bayesian Optimization with Optuna\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 30)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (active_machine_learning)",
   "language": "python",
   "name": "active_machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
